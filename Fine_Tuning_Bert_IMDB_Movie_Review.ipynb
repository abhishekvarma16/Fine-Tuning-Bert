{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es3RDMZvCNwN"
      },
      "source": [
        "# Fine-Tuning Bert on IMDB Movie Review Dataset\n",
        "\n",
        "## Introduction\n",
        "\n",
        "BERT is a powerful language model developed by Google. Its ability to understand the context of words in a sentence makes it particularly well-suited for sentiment analysis tasks.\n",
        "\n",
        "The IMDB dataset is a collection of 50,000 movie reviews, each labeled as positive or negative. In this notebook, we will fine-tune a pre-trained BERT model to achieve high accuracy on sentiment classification of movie reviews.\n",
        "\n",
        "**Note:** This notebook requires a GPU to run efficiently due to the computational demands of fine-tuning BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDle1buFtXGc"
      },
      "source": [
        "## Installing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWHaP2KusoUR",
        "outputId": "19440db2-5e1f-42f4-ea88-c19d84ea44ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install scikit-learn;\n",
        "!pip install datasets\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_QubZ_wvYlA"
      },
      "source": [
        "## Importing Libraries\n",
        "\n",
        "Here we import the necessary libraries for our task. These libraries provide tools for data handling, working with the BERT model, and evaluating our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sMuLDpjvS0c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Token Setup\n",
        "\n",
        "This cell handles authentication with Hugging Face. It retrieves your Hugging Face token, which you need to obtain and store securely beforehand. This token allows us to download the pre-trained BERT model.\n",
        "\n",
        "**Follow these steps to get your Hugging Face token and add it to Colab:**\n",
        "\n",
        "1. **Get your Hugging Face Token:**\n",
        "   * Go to the Hugging Face website (https://huggingface.co/) and log in to your account.\n",
        "   * Click on your profile picture in the top right corner.\n",
        "   * Select \"Settings\".\n",
        "   * In the left sidebar, click on \"Access Tokens\".\n",
        "   * Click on \"New token\".\n",
        "   * Give your token a name (e.g., \"Colab Token\").\n",
        "   * Under \"Role\", select \"Read\".\n",
        "   * Click \"Create\".\n",
        "   * **Important:** Copy the token value that's generated. This is your `HF_TOKEN`. Store it securely.\n",
        "\n",
        "2. **Store your Token in Colab Secrets:**\n",
        "   * In this Colab notebook, click on the \"Secrets\" tab in the left sidebar (it looks like a key).\n",
        "   * Click on \"Add a new secret\".\n",
        "   * In the \"Name\" field, enter `HF_TOKEN`.\n",
        "   * In the \"Value\" field, paste your Hugging Face token that you copied earlier.\n",
        "   * Click \"Add\".\n",
        "\n",
        "Now you can run the code below to log in to Hugging Face."
      ],
      "metadata": {
        "id": "BzgXc8mNeYCZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j1CaX7R9lVT",
        "outputId": "abc43651-2ce3-481d-892c-5069b142e3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `READ_AGAIN` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `READ_AGAIN`\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "hf_token=userdata.get('HF_TOKEN')\n",
        "\n",
        "# Now, you can use the token to authenticate with Hugging Face\n",
        "!huggingface-cli login --token \"$hf_token\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awqASFxeRbTx"
      },
      "source": [
        "## Download the IMDB Dataset\n",
        "\n",
        "This cell downloads the IMDB dataset directly from Kaggle.\n",
        "\n",
        "**Before running this code, follow these steps to set up the Kaggle API:**\n",
        "\n",
        "1. **Create a Kaggle Account:** If you don't have one already, create an account on Kaggle (https://www.kaggle.com/).\n",
        "2. **Get your Kaggle API Token:** Go to your Kaggle account settings, and under the 'API' section, click 'Create New API Token'. This will download a `kaggle.json` file.\n",
        "3. **Upload `kaggle.json` to Colab:** In the Files tab of this Colab notebook, click 'Upload' and select the downloaded `kaggle.json` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ62MABdRarv",
        "outputId": "c0878d0a-7215-477e-f147-2ee6be945820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
            "License(s): other\n",
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content\n",
            " 89% 23.0M/25.7M [00:02<00:00, 22.8MB/s]\n",
            "100% 25.7M/25.7M [00:02<00:00, 12.5MB/s]\n",
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "! unzip imdb-dataset-of-50k-movie-reviews.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t13gSXX3RHm"
      },
      "source": [
        "## Manual Dataset Upload (Optional)\n",
        "\n",
        "If you prefer to upload the dataset manually (e.g., if you have the dataset file on your local machine), you can use this method. However, keep in mind that uploading large files to Colab can be slow.\n",
        "\n",
        "To use this, uncomment the code. Then, run the cell. This will prompt you to select the dataset file from your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvJVSv2h1tAU"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # This will prompt you to upload files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN2iYtvS15AZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.rename('/content/IMDB Dataset.csv', '/content/imdb_dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6MNLWZTXIHj"
      },
      "source": [
        "## Key Customizable Variables\n",
        "This section defines key variables that control the behavior of the model and training process. You can adjust these values to experiment with different settings and potentially improve performance.\n",
        "\n",
        "The default values are chosen to work well in the Colab environment on free tier, which has limited memory. If you are running this notebook on a machine with more resources, you can increase some of these values (e.g., `my_max_length`, `sample_size`, `batch_size`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tIrw2rcE57q"
      },
      "outputs": [],
      "source": [
        "# This section contains key variables that can be adjusted based on the environment or use case.\n",
        "# For Colab, we set conservative defaults to avoid memory issues.\n",
        "\n",
        "# Maximum token length for tokenizer (adjust based on text length and memory limits)\n",
        "my_max_length = 256  # This can be adjusted as needed for different datasets\n",
        "\n",
        "# Sample size for dataset reduction (set to a small number to avoid memory issues in Colab)\n",
        "sample_size = None  # Total samples: 25 positive, 25 negative\n",
        "\n",
        "# Number of training epochs (can reduce or increase based on dataset size and overfitting concerns)\n",
        "num_train_epochs = 3  # Adjust this for faster or slower training\n",
        "\n",
        "# Learning rate for the optimizer\n",
        "learning_rate = 3e-5  # Smaller values often result in more stable learning\n",
        "\n",
        "# Early stopping patience to avoid overfitting\n",
        "early_stopping_patience = 2  # Stop training if no improvement after this many evaluations\n",
        "\n",
        "#Batch size of data for training\n",
        "train_batch_size = 16  # Adjust based on available memory\n",
        "\n",
        "# Batch size of data for evaluation\n",
        "eval_batch_size = 16  # Adjust based on available memory\n",
        "\n",
        "# Warmup steps for learning rate scheduler\n",
        "warmup_steps = 500  # Increase if the learning rate schedule needs a slower start\n",
        "\n",
        "# Logging steps (how often to log during training)\n",
        "logging_steps = 10  # Adjust to log more or less frequently during training\n",
        "\n",
        "# Evaluation steps (how often to evaluate the model during training)\n",
        "eval_steps = 500  # Evaluate the model every 500 steps\n",
        "\n",
        "# Save steps (how often to save model checkpoints)\n",
        "save_steps = 500  # Save model every 500 steps\n",
        "\n",
        "# Weight decay for regularization (use a small value to prevent overfitting)\n",
        "weight_decay = 0.1  # Adjust for stronger or weaker regularization\n",
        "\n",
        "# Test size for splitting dataset\n",
        "test_size = 0.2  # 20% of the dataset will be used for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9UBBZbep46P"
      },
      "source": [
        "## Loading the IMDB Movie Review Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3IH9a7Wrv8v"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "df = pd.read_csv('/content/imdb_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cMo0Zt81Wisj",
        "outputId": "cdf7fcf9-6107-412f-c253-4c8d92e2ff69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ad070bc-8f6d-48c1-8a9d-6b4adb824303\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ad070bc-8f6d-48c1-8a9d-6b4adb824303')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ad070bc-8f6d-48c1-8a9d-6b4adb824303 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ad070bc-8f6d-48c1-8a9d-6b4adb824303');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71d45d01-688e-4ce2-a553-8d04544033c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71d45d01-688e-4ce2-a553-8d04544033c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71d45d01-688e-4ce2-a553-8d04544033c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pFYr9DHXcu4"
      },
      "source": [
        "## Balance the Dataset (Optional)\n",
        "\n",
        "This function creates a balanced subset of the data, ensuring an equal number of positive and negative reviews. This can be helpful for preventing the model from being biased towards one sentiment class.\n",
        "\n",
        "If you set the `sample_size` variable in the 'Configuration' section, this function will be used to create a smaller, balanced dataset. If `sample_size` is set to `None`, the full dataset will be used.\n",
        "\n",
        "**Explanation of the `create_subset` function:**\n",
        "\n",
        "1. Converts the 'sentiment' column to binary labels (1 for positive, 0 for negative).\n",
        "2. If `sample_size` is provided, it samples an equal number of positive and negative reviews.\n",
        "3. Concatenates the samples and shuffles the data.\n",
        "4. If no `sample_size` is provided, it uses the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-t6b2usXa3i",
        "outputId": "05d2a9c2-86d5-4b9d-8cc8-a27dfeb82482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No sample size given. Using entire dataset\n"
          ]
        }
      ],
      "source": [
        "def create_subset(dataframe, sample_size=None, random_seed=42):\n",
        "    # Convert sentiment into binary labels (1 for positive, 0 for negative)\n",
        "    dataframe['label'] = dataframe['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "    if sample_size:\n",
        "        # Separate positive and negative reviews\n",
        "        positive_reviews = dataframe[dataframe['label'] == 1]\n",
        "        negative_reviews = dataframe[dataframe['label'] == 0]\n",
        "\n",
        "        # Sample the specified number of rows from each class\n",
        "        positive_sample = positive_reviews.sample(n=sample_size, random_state=random_seed)\n",
        "        negative_sample = negative_reviews.sample(n=sample_size, random_state=random_seed)\n",
        "\n",
        "        # Concatenate the samples and shuffle\n",
        "        subset_df = pd.concat([positive_sample, negative_sample]).sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "    else:\n",
        "        # If no sample size is provided, use the full dataset\n",
        "        print(\"No sample size given. Using entire dataset\")\n",
        "        subset_df = dataframe.copy()\n",
        "\n",
        "    return subset_df\n",
        "\n",
        "# Run the function to create a smaller subset of the data\n",
        "reduced_df = create_subset(df, sample_size=sample_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na5QpZzUySVj",
        "outputId": "41fb654f-5053-482d-fcad-63a9ef1ece03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment  label\n",
            "0  One of the other reviewers has mentioned that ...  positive      1\n",
            "1  A wonderful little production. <br /><br />The...  positive      1\n",
            "2  I thought this was a wonderful way to spend ti...  positive      1\n",
            "3  Basically there's a family where a little boy ...  negative      0\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1\n"
          ]
        }
      ],
      "source": [
        "print(reduced_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dBmcspmx5Vr",
        "outputId": "60ed8545-698b-44cf-b1eb-0381594b3267"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "reduced_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf7CRQn0vAHP"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Data preprocessing is a crucial step in Natural Language Processing (NLP). It helps to clean and standardize the text data, making it easier for the model to learn meaningful patterns.\n",
        "\n",
        "This cell performs some preprocessing on the review text. It removes HTML tags and any unnecessary characters that might not be relevant for sentiment analysis. It also adds a 'label' column with numerical representations of the sentiment (1 for positive, 0 for negative)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49CbYFzH00lC"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
        "    # Remove any other unnecessary characters or punctuations\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "reduced_df['review'] = reduced_df['review'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8fX9aoq2D2m"
      },
      "source": [
        "## Data Preprocessing Example\n",
        "\n",
        "This cell provides an example of how the `clean_text` function removes HTML tags and unnecessary characters from the review text. It helps you visualize the effect of the preprocessing step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYIy7CD-xfUO",
        "outputId": "26ba821f-4e3e-424b-db4f-6c85cd42d91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Review:\n",
            "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n",
            "\n",
            "Cleaned Review:\n",
            "A wonderful little production   The filming technique is very unassuming very oldtimeBBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece   The actors are extremely well chosen Michael Sheen not only has got all the polari but he has all the voices down pat too You can truly see the seamless editing guided by the references to Williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece A masterful production about one of the great masters of comedy and his life   The realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets particularly of their flat with Halliwells murals decorating every surface are terribly well done\n"
          ]
        }
      ],
      "source": [
        "# Sample review with HTML tags and special characters\n",
        "sample_review = df['review'].iloc[1]  # Taking the first review from the dataset as a sample\n",
        "\n",
        "# Original review\n",
        "print(\"Original Review:\")\n",
        "print(sample_review)\n",
        "\n",
        "# Cleaned review\n",
        "cleaned_review = clean_text(sample_review)\n",
        "print(\"\\nCleaned Review:\")\n",
        "print(cleaned_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V5sv4Xm-vPYv",
        "outputId": "826f8e45-494d-4a24-b053-5e8bf37ff967"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  label\n",
              "0  One of the other reviewers has mentioned that ...  positive      1\n",
              "1  A wonderful little production   The filming te...  positive      1\n",
              "2  I thought this was a wonderful way to spend ti...  positive      1\n",
              "3  Basically theres a family where a little boy J...  negative      0\n",
              "4  Petter Matteis Love in the Time of Money is a ...  positive      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b483ecc4-d260-4e4e-b45d-d22efa60889e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production   The filming te...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically theres a family where a little boy J...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Matteis Love in the Time of Money is a ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b483ecc4-d260-4e4e-b45d-d22efa60889e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b483ecc4-d260-4e4e-b45d-d22efa60889e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b483ecc4-d260-4e4e-b45d-d22efa60889e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b27f692-1c31-475e-9b41-6b8d24f2f452\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b27f692-1c31-475e-9b41-6b8d24f2f452')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b27f692-1c31-475e-9b41-6b8d24f2f452 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reduced_df",
              "summary": "{\n  \"name\": \"reduced_df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49581,\n        \"samples\": [\n          \"Poorly done political actioner Badly photographed acted and directed Every single scene is underlighted including those very few that are shot during the daytime It doesnt matter what the location is At an important conference in the White House no lights are on and the only available lighting is a gloomy blue that is filtered through a few windows The primier of China conducts an earthshattering phone conversation under conditions of such intense chiaroscuro that he should be contemplating a bust of Homer in a Rembrandt painting Honest Its as if he had a tiny spotlight on his face and was otherwise in total darkness The slow motion deaths are by now obligatory in any illthoughtout movie  Roy Scheider and Maria Conchita Alonzo do well by their roles but Scheider is rarely on screen The other performances are dismissable There is a pretty Oriental woman in a short tight skirt who totes a gun and is right out of a Bond movie whos accent suggests a childhood spent in Basset Nebraska and who should have remained the model she probably started out as Whoever plays the surviving Secret Service agent aboard the cruise ship was probably picked for the part because he looked most like Johnny Depp not because of any display of talent The Chinese villains representing both Taiwan and mainland China hiss and grin as they threaten the heroes   The script is pretty awful recycled from other better films There is a lot of shooting aboard the ship and practically everyone winds up mincemeat Two thirds of the way through the ship explodes into the expected series of fireballs Then the movie splits into two related parts Part one another shootout this time in a waterfront warehouse Part two an exchange between the Vice President now acting president and the oily Chinese premiere lifted out of both Dr Strangelove and Fail Safe We unwittingly launch our missiles They launch theirs in retaliation We cannot convince them that our launch was accidental even though we offer to help them destroy our own missiles There is even the George C Scott Walter Matthau general who argues that their nucular armory cant match ours so we should hit them with everything weve got More fireballs   The end comes none too soon\",\n          \"Not good Mostly because you dont give a damn about what happens to all these people Some comments  1 I am tired of seeing governesses who never talk to their pupils never teach them anything and take a tired and annoyed look whenever the said pupil who of course has been won over in the space of 4 seconds says something 2 Fine so Rosina has a father complex and therefore is attracted to her employer But Charles is completely different in all aspects from her father  if anything Henry is much closer as a sensual exalted person 3 How could you ever believe that she would be more attracted to Tom Wilkinson than to Rhys Meyer 4 Hard to believe if she had been in fact raised as a deeply religious girl that she would be so careless about sleeping with a gentile after knowing him for 5 minutes  Some good things about the film  At least she didnt end up pregnant not knowing who the father was The whole description of life in the Jewish community in London is good\",\n          \"FUTZ is the only show preserved from the experimental theatre movement in New York in the 1960s the origins of Off Off Broadway Though its not for everyone it is a genuinely brilliant darkly funny even more often deeply disturbing tale about love sex personal liberty and revenge a serious morality tale even more relevant now in a time when Congress wants to outlaw gay marriage by trashing our Constitution The story is not about being gay though  its about love and sex that dont conform to social norms and therefore must be removed through violence and hate On the surface it tells the story of a man who falls in love with a pig but like any great fable its not really about animals its about something bigger  stifling conformity in America  The stage version won international acclaim in its original production it toured the US and Europe and with others of its kind influenced almost all theatre that came after it Luckily we have preserved here the show pretty much as it was originally conceived with the original cast and original director Tom OHorgan who also directed HAIR and Jesus Christ Superstar on Broadway  This is not a mainstream easytotake studio film  this is an aggressive unsettling glorious deeply emotional wildly imaginative piece of storytelling that youll never forget And it just might change the way you see the world\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "reduced_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qRJtzxd8cVf"
      },
      "source": [
        "## Determine Maximum Sequence Length\n",
        "\n",
        "Before we can feed our text data into the BERT model, we need to tokenize it (convert the words into numerical representations). BERT requires that all input sequences have the same length. This cell helps us determine an appropriate maximum sequence length for our dataset.\n",
        "\n",
        "**Tokenization:**\n",
        "\n",
        "Tokenization is the process of breaking down text into individual units called tokens. These tokens can be words, subwords, or characters, depending on the tokenizer used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "c1c805b3f9be4f6ab3dfc4e6391e53d8",
            "ebc0b9283b9944df94d93f3dd0b25de1",
            "24c075f9ad234831812f4110667b420b",
            "2cbae121875e455eab445274ed1c7f25",
            "4be0ab76cf674a91815dade8093b0b57",
            "3adb4c4afc30496298dac4b2a1ae8fba",
            "a1607cecfd00477aa839b1965a9bd6be",
            "a685253f9323487188168eaecffc20f9",
            "dbc803c3ae04423b9f685ca1528188f6",
            "72ac20b8957149fa81e5e143b7667ef2",
            "e3748f3465264549b833639a4af46cea",
            "5a22d610c4d44f23ae39fc881cdea4e8",
            "6ef683bc18b74093b1726d1d35c121cb",
            "2376b28c58324d86ab756547995269b5",
            "7cb921148c514cd8b43c88af451b04ab",
            "5fcde940ca424009900586ba01582581",
            "94173eb3858c4aed837e696075621b3a",
            "c5337660558e4af297d3ccbcecb857da",
            "486595e6c9784687b3c3057c3a9b3ff8",
            "82d61bef313746ccb84ff4ef2c504ea5",
            "0cfd57048fc4413c87b90888a6aa6dda",
            "c2f98f7e4c4c494eb2efa3c5abfad4c2",
            "4a51826a82a443f4aea03084a6d7a50d",
            "b2caab0d9d51459c93fcc02250a05ca9",
            "74b133ba7b404c208b2b912e29016c81",
            "e2c0fa0051634b339719bcbbd2cfb5bb",
            "d16c844b265f4e2b9026285ca8d47d40",
            "98f57d4edf074791a9ccacc662724a8f",
            "d8b306981b6f4f418c17491538094cea",
            "90f01cda9dc84d8b8298c7056f703a71",
            "e240316149b74600810640d7f78bdd05",
            "5a2c263e2da04ad9ae46055dfa094a89",
            "794f0d276d1547db9055f056c9cb3c93",
            "560827baa14e478bb1ca555efbb7d043",
            "25515eb1d22e401d9217324b835beef5",
            "d4c00a65761f42a68244f63414743b8c",
            "6ed102c22bc54748a459a2142f3a1891",
            "f84efdcfed264190bf30196b9212f01b",
            "bc2e32bfbeae48829793ce503022d4d7",
            "20e402c074aa4f21a4504983f301a31c",
            "b2abb00a39d64a00801acbb1f69f1067",
            "a2a4201f8ca9437b979598180d654dcf",
            "8114b5aa2db94ee886524244e3093fa5",
            "e563c60497b844069bfc57b1322b99b7"
          ]
        },
        "id": "hnoatHllwZF8",
        "outputId": "7c0e144d-e4f8-4415-aca8-b1bd93abd1dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1c805b3f9be4f6ab3dfc4e6391e53d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a22d610c4d44f23ae39fc881cdea4e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a51826a82a443f4aea03084a6d7a50d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "560827baa14e478bb1ca555efbb7d043"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    50000.000000\n",
            "mean       251.293260\n",
            "std        187.828859\n",
            "min          6.000000\n",
            "25%        136.000000\n",
            "50%        188.000000\n",
            "75%        305.000000\n",
            "max       2732.000000\n",
            "Name: review_length, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "reduced_df['review_length'] = reduced_df['review'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
        "\n",
        "# Display basic statistics about review lengths\n",
        "print(reduced_df['review_length'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stUq6YRUGbvp"
      },
      "source": [
        "# Tokenizing the dataset so that Bert can work with it.\n",
        "## Note: This process might take several minutes to complete\n",
        "\n",
        "\n",
        "\n",
        "BERT, like other Transformer models, doesn't work directly with raw text. It requires numerical input. This cell tokenizes the dataset, converting the text into numerical representations that BERT can understand.\n",
        "\n",
        "The `tokenize_function` uses the `my_max_length` variable (defined earlier) to ensure all tokenized sequences have the same length. Sequences longer than `my_max_length` are truncated, and shorter sequences are padded.\n",
        "\n",
        "The `tokenizer` function returns a dictionary containing three important elements:\n",
        "\n",
        "* `input_ids`: The numerical representations of the tokens.\n",
        "* `attention_mask`: Indicates which tokens should be attended to (1 for actual tokens, 0 for padding tokens).\n",
        "* `token_type_ids`: (Optional) Used when processing sentence pairs to distinguish between the sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8pXLWoWAFqi",
        "outputId": "02d2eb11-2af4-4a08-a90b-ced72ebec032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 2028, 1997, 1996, 2060, 15814, 2038, 3855, 2008, 2044, 3666, 2074, 1015, 11472, 2792, 2017, 3363, 2022, 13322, 2027, 2024, 2157, 2004, 2023, 2003, 3599, 2054, 3047, 2007, 2033, 1996, 2034, 2518, 2008, 4930, 2033, 2055, 11472, 2001, 2049, 24083, 1998, 4895, 10258, 2378, 8450, 5019, 1997, 4808, 2029, 2275, 1999, 2157, 2013, 1996, 2773, 2175, 3404, 2033, 2023, 2003, 2025, 1037, 2265, 2005, 1996, 8143, 18627, 2030, 5199, 3593, 2023, 2265, 8005, 2053, 17957, 2007, 12362, 2000, 5850, 3348, 2030, 4808, 2049, 2003, 13076, 1999, 1996, 4438, 2224, 1997, 1996, 2773, 2009, 2003, 2170, 11472, 2004, 2008, 2003, 1996, 8367, 2445, 2000, 1996, 17411, 4555, 3036, 2110, 7279, 4221, 12380, 2854, 2009, 7679, 3701, 2006, 14110, 2103, 2019, 6388, 2930, 1997, 1996, 3827, 2073, 2035, 1996, 4442, 2031, 3221, 21430, 1998, 2227, 20546, 2015, 2061, 9394, 2003, 2025, 2152, 2006, 1996, 11376, 7861, 2103, 2003, 2188, 2000, 2116, 5649, 6962, 7486, 18542, 10230, 7402, 2015, 8135, 16773, 3493, 1998, 2062, 6499, 8040, 16093, 28331, 2331, 14020, 26489, 6292, 24069, 1998, 22824, 10540, 2024, 2196, 2521, 2185, 1045, 2052, 2360, 1996, 2364, 5574, 1997, 1996, 2265, 2003, 2349, 2000, 1996, 2755, 2008, 2009, 3632, 2073, 2060, 3065, 2876, 2102, 8108, 5293, 3492, 4620, 4993, 2005, 7731, 9501, 5293, 11084, 5293, 7472, 18153, 2987, 2102, 6752, 2105, 1996, 2034, 2792, 1045, 2412, 2387, 4930, 2033, 2004, 2061, 11808, 2009, 2001, 16524, 1045, 2481, 2102, 2360, 1045, 2001, 3201, 2005, 2009, 2021, 2004, 1045, 3427, 2062, 1045, 2764, 1037, 5510, 2005, 11472, 1998, 2288, 17730, 2000, 102]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def tokenize_function(row):\n",
        "    return tokenizer(row['review'], padding='max_length', truncation=True, max_length=my_max_length) #using max_length as 256 since it seems reasonable considering above results\n",
        "\n",
        "# Apply the tokenizer to each row of the dataset\n",
        "tokenized_dataset = reduced_df.copy()\n",
        "tokenized_dataset['tokenized'] = tokenized_dataset.apply(tokenize_function, axis=1)\n",
        "\n",
        "# Since the tokenizer returns a dictionary, you need to separate the components\n",
        "# Create separate columns for input_ids, attention_mask, etc.\n",
        "tokenized_dataset['input_ids'] = tokenized_dataset['tokenized'].apply(lambda x: x['input_ids'])\n",
        "tokenized_dataset['attention_mask'] = tokenized_dataset['tokenized'].apply(lambda x: x['attention_mask'])\n",
        "# If needed, you can also extract 'token_type_ids' or any other components\n",
        "\n",
        "# Now you can drop the 'tokenized' column since you've extracted what you need\n",
        "tokenized_dataset = tokenized_dataset.drop(columns=['tokenized'])\n",
        "\n",
        "# Display a sample of the tokenized data\n",
        "print(tokenized_dataset['input_ids'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsXB8txP2ewl"
      },
      "source": [
        "## Tokenization Example\n",
        "\n",
        "This cell provides a concrete example of the tokenization process. It shows how a sample review from the dataset is transformed into numerical `input_ids` and an `attention_mask`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZjNBm8itUm0",
        "outputId": "53172459-d8d5-4f5d-ac1c-51261e641f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "\n",
            "Tokenized input IDs:\n",
            "[101, 2028, 1997, 1996, 2060, 15814, 2038, 3855, 2008, 2044, 3666, 2074, 1015, 11472, 2792, 2017, 1005, 2222, 2022, 13322, 1012, 2027, 2024, 2157, 1010, 2004, 2023, 2003, 3599, 2054, 3047, 2007, 2033, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2034, 2518, 2008, 4930, 2033, 2055, 11472, 2001, 2049, 24083, 1998, 4895, 10258, 2378, 8450, 5019, 1997, 4808, 1010, 2029, 2275, 1999, 2157, 2013, 1996, 2773, 2175, 1012, 3404, 2033, 1010, 2023, 2003, 2025, 1037, 2265, 2005, 1996, 8143, 18627, 2030, 5199, 3593, 1012, 2023, 2265, 8005, 2053, 17957, 2007, 12362, 2000, 5850, 1010, 3348, 2030, 4808, 1012, 2049, 2003, 13076, 1010, 1999, 1996, 4438, 2224, 1997, 1996, 2773, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 2003, 2170, 11472, 2004, 2008, 2003, 1996, 8367, 2445, 2000, 1996, 17411, 4555, 3036, 2110, 7279, 4221, 12380, 2854, 1012, 2009, 7679, 3701, 2006, 14110, 2103, 1010, 2019, 6388, 2930, 1997, 1996, 3827, 2073, 2035, 1996, 4442, 2031, 3221, 21430, 1998, 2227, 20546, 2015, 1010, 2061, 9394, 2003, 2025, 2152, 2006, 1996, 11376, 1012, 7861, 2103, 2003, 2188, 2000, 2116, 1012, 1012, 26030, 2015, 1010, 7486, 1010, 18542, 10230, 1010, 7402, 2015, 1010, 8135, 1010, 16773, 1010, 3493, 1998, 2062, 1012, 1012, 1012, 1012, 2061, 8040, 16093, 28331, 1010, 2331, 14020, 1010, 26489, 6292, 24069, 1998, 22824, 10540, 2024, 2196, 2521, 2185, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2052, 2360, 1996, 2364, 5574, 1997, 1996, 2265, 2003, 2349, 2000, 1996, 2755, 2008, 2009, 3632, 2073, 2060, 3065, 2876, 1005, 102]\n",
            "\n",
            "Attention Mask:\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "sample_text = df['review'].iloc[0]  # Taking the first review from the dataset as a sample\n",
        "\n",
        "# Tokenize the sample text\n",
        "tokenized_sample = tokenizer(sample_text, padding='max_length', truncation=True, max_length=my_max_length)\n",
        "\n",
        "# Display the original and tokenized data\n",
        "print(\"Original Text:\")\n",
        "print(sample_text)\n",
        "\n",
        "print(\"\\nTokenized input IDs:\")\n",
        "print(tokenized_sample['input_ids'])\n",
        "\n",
        "print(\"\\nAttention Mask:\")\n",
        "print(tokenized_sample['attention_mask'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJRBC7f64hYf"
      },
      "source": [
        "## Tokenized Sequence Length Analysis\n",
        "\n",
        "This cell analyzes the lengths of the tokenized sequences. This analysis helps to understand the distribution of sequence lengths and ensures that our `my_max_length` parameter is appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "-4y6XTZx4gLx",
        "outputId": "c8a8bd19-d047-4832-d80d-838cf2482baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sequence length: 256.00\n",
            "Minimum sequence length: 256\n",
            "Maximum sequence length: 256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of reviews exceeding max_length (256 tokens): 0.00%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the lengths of tokenized input sequences (number of tokens per review)\n",
        "token_lengths = tokenized_dataset['input_ids'].apply(len)\n",
        "\n",
        "# 1. Average sequence length\n",
        "average_length = np.mean(token_lengths)\n",
        "print(f\"Average sequence length: {average_length:.2f}\")\n",
        "\n",
        "# 2. Minimum and maximum sequence lengths\n",
        "min_length = np.min(token_lengths)\n",
        "max_length = np.max(token_lengths)\n",
        "print(f\"Minimum sequence length: {min_length}\")\n",
        "print(f\"Maximum sequence length: {max_length}\")\n",
        "\n",
        "# 3. Histogram of sequence lengths\n",
        "plt.hist(token_lengths, bins=20, color='blue', alpha=0.7)\n",
        "plt.title(\"Distribution of Sequence Lengths\")\n",
        "plt.xlabel(\"Sequence Length\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Percentage of reviews exceeding the max length (256 in this case)\n",
        "max_length_threshold = 256\n",
        "exceeding_max_length = np.sum(token_lengths > max_length_threshold)\n",
        "percentage_exceeding = (exceeding_max_length / len(token_lengths)) * 100\n",
        "print(f\"Percentage of reviews exceeding max_length ({max_length_threshold} tokens): {percentage_exceeding:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WfJ9eYB7E-t"
      },
      "source": [
        "## What is an Attention Mask?\n",
        "\n",
        "Transformer models like BERT process input sequences in batches. To handle sequences of different lengths within a batch, shorter sequences are padded with special tokens to make them all the same length.  \n",
        "\n",
        "The attention mask is a crucial component that helps the model distinguish between actual words and padding tokens. It's a binary mask (consisting of 0s and 1s) that tells the model which tokens to \"pay attention to\" and which ones to ignore.\n",
        "\n",
        "**Here's how it works:**\n",
        "\n",
        "* **1:** Indicates an actual word token that should be considered.\n",
        "* **0:** Indicates a padding token that should be ignored.\n",
        "\n",
        "This ensures that the model focuses on the meaningful content of the input and doesn't get confused by the padding tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjSxC1927Ei2",
        "outputId": "1faa87f9-4741-4218-b9b5-0cd33f2e51b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Mask Example:\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "sample_text = df['review'].iloc[1]  # Taking the first review from the dataset as an example\n",
        "tokenized_sample = tokenizer(sample_text, padding='max_length', truncation=True, max_length=256)\n",
        "\n",
        "print(\"Attention Mask Example:\")\n",
        "print(tokenized_sample['attention_mask'])  # Display the attention mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odi7lbRnuo_D"
      },
      "source": [
        "## Prepare Data for Training\n",
        "\n",
        "Now that the dataset is tokenized, we need to split it into training and validation sets. This allows us to train the model on one portion of the data and evaluate its performance on a separate, unseen portion.\n",
        "\n",
        "This cell performs the following steps:\n",
        "\n",
        "1. **Import `train_test_split`:** Imports the function used to split the data.\n",
        "2. **Select relevant columns:** Selects the `input_ids`, `attention_mask`, and `label` columns, which are needed for training.\n",
        "3. **Split the data:** Splits the data into training and validation sets using the `train_test_split` function. The `test_size` parameter determines the proportion of data used for validation.\n",
        "4. **Display set sizes:** Prints the number of samples in the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrrCtnsJEOuQ",
        "outputId": "9515cdfa-0b5b-4390-f456-bf7cafa413d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 40000\n",
            "Validation set size: 10000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Select the relevant columns for training and validation\n",
        "input_columns = ['input_ids', 'attention_mask', 'label']\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(tokenized_dataset[input_columns], test_size=test_size, random_state=1)\n",
        "\n",
        "# Display the number of samples in each set\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJk7U-kCUqOK"
      },
      "source": [
        "## Create Hugging Face Datasets\n",
        "\n",
        "The `transformers` library provides a convenient way to train models using the `Trainer` class. This class works seamlessly with Hugging Face Datasets. So, in this cell, we convert our training and validation DataFrames into Hugging Face Dataset objects.\n",
        "\n",
        "This makes it easier to manage the data during training and leverage the features of the `Trainer` API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8_aiyMVJ10i",
        "outputId": "7d1a7b50-60db-4d83-e293-ffc3c1152a5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 2023, 2143, 2038, 2042, 4102, 2000, 1996, 26316, 2329, 4038, 1037, 3869, 2170, 20848, 2348, 1045, 2064, 2102, 2156, 2339, 1996, 2069, 4434, 1045, 2064, 2424, 2003, 1996, 18446, 18750, 2028, 4388, 18373, 1999, 16752, 2198, 18856, 10285, 2063, 1998, 2745, 28619, 2078, 1999, 20848, 4728, 1996, 2048, 2024, 4297, 25377, 25236, 18373, 1998, 12289, 9110, 18053, 2024, 2048, 20067, 2015, 2040, 2215, 2000, 2131, 2041, 1997, 1996, 2449, 2077, 2027, 2203, 2039, 2757, 2061, 2027, 5630, 2000, 10973, 2125, 2037, 5795, 1998, 2191, 2005, 5673, 2043, 1996, 2131, 9497, 3632, 3308, 1996, 2048, 2024, 3140, 2000, 2202, 9277, 1999, 1037, 10664, 2004, 16752, 2054, 2012, 2034, 10659, 2000, 2022, 1037, 11421, 2574, 4150, 1037, 21425, 2779, 3185, 2007, 1996, 5156, 5510, 3238, 3348, 13198, 1998, 20857, 17211, 2320, 2153, 2045, 2024, 1996, 8138, 2152, 7516, 2021, 4445, 3459, 4496, 3626, 6133, 2000, 18708, 8931, 2019, 3535, 2012, 1037, 20848, 2828, 23624, 2278, 3926, 11896, 2205, 2247, 2007, 1996, 3947, 2012, 2273, 1999, 8011, 17211, 2029, 2003, 6684, 11341, 2043, 2017, 2228, 2055, 2009, 2273, 2667, 2000, 2022, 2308, 2003, 6057, 2273, 2667, 2000, 2022, 16752, 2003, 9951, 5958, 2258, 2570, 2807, 2678, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, '__index_level_0__': 18165}\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convert the training and validation DataFrames to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "print(train_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ZGeVR00d5Y"
      },
      "source": [
        "## Load the Pre-trained BERT Model\n",
        "\n",
        "Now it's time to load the pre-trained BERT model that we'll fine-tune for sentiment analysis.\n",
        "\n",
        "This cell uses the `BertForSequenceClassification` class from the `transformers` library to load a pre-trained BERT model. We use the `bert-base-uncased` variant, which is a smaller version of BERT that is case-insensitive.\n",
        "\n",
        "The `num_labels=2` argument specifies that we have two output labels (positive and negative)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "84f046e75cde40e3a45d331aeab3bce3",
            "5300624331a8478c969eb8e7ce6589e2",
            "284fb5d182264ef5b35d513ce01a22f3",
            "a5a62ab1ffcb4b478436b7139bced883",
            "6fe625d128cf40e49079a8e209abe2c1",
            "6573859f5e8f498fbc068d8cb07f6e54",
            "6c25fa552d484366a15ad0cd41f94926",
            "c691a139c88744f28f6285d210b05154",
            "fd8bc091dd71488bafaba01150f8c5d2",
            "cb12c92a63724c0fbe5e01659a09b622",
            "7498e23213b445e9bce845d04f213f63"
          ]
        },
        "id": "D0GhVbkzvBHK",
        "outputId": "04ec714f-d1a8-48b3-cc79-40470e2aaa7d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84f046e75cde40e3a45d331aeab3bce3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwsYPkmo1UZl"
      },
      "source": [
        "## Configure Training Parameters\n",
        "\n",
        "This cell sets up the training parameters using the `TrainingArguments` class from the `transformers` library. These arguments control various aspects of the training process, such as:\n",
        "\n",
        "* **`output_dir`:**  The directory where the trained model and checkpoints will be saved.\n",
        "* **`num_train_epochs`:** The number of times the model will be trained on the entire training dataset.\n",
        "* **`per_device_train_batch_size`:** The batch size for training.\n",
        "* **`per_device_eval_batch_size`:** The batch size for evaluation.\n",
        "* **`warmup_steps`:** The number of warmup steps for the learning rate scheduler.\n",
        "\n",
        "* **`weight_decay`:**  The strength of weight decay (a regularization technique).\n",
        "* **`logging_dir`:** The directory for storing training logs.\n",
        "* **`logging_steps`:** How often to log training information (in number of steps).\n",
        "* **`evaluation_strategy`:**  When to evaluate the model during training (\"epoch\" means at the end of each iteration).\n",
        "\n",
        "You can adjust these parameters to experiment with different training settings and potentially improve the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjiEDhGq0Pi9",
        "outputId": "562e484c-9aa3-4052-dfd0-f38e93a95056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # Output directory\n",
        "    num_train_epochs=num_train_epochs,               # Number of training epochs\n",
        "    per_device_train_batch_size=train_batch_size,   # Batch size for training\n",
        "    per_device_eval_batch_size=eval_batch_size,    # Batch size for evaluation\n",
        "    warmup_steps=warmup_steps,                 # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=weight_decay,                # Strength of weight decay\n",
        "    logging_dir='./logs',             # Directory for storing logs\n",
        "    logging_steps=logging_steps,                 # Log every 10 steps\n",
        "    evaluation_strategy=\"epoch\"       # Evaluate at the end of every epoch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf7koC858oiY"
      },
      "source": [
        "## Fine-tuning with Overfitting Prevention\n",
        "\n",
        "This cell sets up the training parameters with a focus on preventing overfitting. Overfitting occurs when the model learns the training data too well and performs poorly on unseen data.\n",
        "\n",
        "Here's how this code addresses overfitting:\n",
        "\n",
        "* **`num_train_epochs`:** Reduces the number of training epochs to prevent the model from memorizing the training data.\n",
        "* **`weight_decay`:** Applies weight decay, a regularization technique that penalizes large weights and helps prevent overfitting.\n",
        "* **`learning_rate`:** Uses a smaller learning rate to make more gradual updates to the model's weights, leading to more stable learning.\n",
        "* **`evaluation_strategy=\"steps\"`:** Evaluates the model more frequently (every 500 steps) to monitor its performance and detect overfitting early on.\n",
        "* **`eval_steps=500`:**  Sets the evaluation frequency to 500 steps.\n",
        "* **`save_steps=500`:** Saves checkpoints every 500 steps, allowing you to revert to earlier versions of the model if overfitting occurs.\n",
        "* **`load_best_model_at_end=True`:** Ensures that the best performing model (based on evaluation metrics) is loaded at the end of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQvYVP-48fi4",
        "outputId": "b1b0873c-6caf-496a-be0f-29e195977ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=num_train_epochs,               # Reduce the number of epochs\n",
        "    per_device_train_batch_size=train_batch_size,   # Set batch size\n",
        "    per_device_eval_batch_size=eval_batch_size,    # Set evaluation batch size\n",
        "    warmup_steps=warmup_steps,                 # Warmup steps\n",
        "    weight_decay=weight_decay,                 # Increase weight decay to reduce overfitting\n",
        "    learning_rate=learning_rate,               # Use a smaller learning rate\n",
        "    logging_dir='./logs',             # Directory for storing logs\n",
        "    logging_steps=logging_steps,                 # Log every 10 steps\n",
        "    evaluation_strategy=\"steps\",      # Evaluate every few steps\n",
        "    eval_steps=eval_steps,                   # Evaluate every 500 steps\n",
        "    save_steps=save_steps,                   # Save checkpoint every 500 steps\n",
        "    load_best_model_at_end=True       # Load the best model at the end of training\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Trainer\n",
        "\n",
        "This cell creates a `Trainer` object, which is a core component of the `transformers` library for training and evaluating models. The `Trainer` simplifies the training process by handling many of the underlying details.\n",
        "\n",
        "Here's what this code does:\n",
        "\n",
        "* **Instantiate `Trainer`:** Creates an instance of the `Trainer` class.\n",
        "* **Provide model and arguments:** Passes the loaded BERT model (`model`) and the training arguments (`training_args`) to the `Trainer`.\n",
        "* **Specify datasets:** Provides the training dataset (`train_dataset`) and validation dataset (`val_dataset`) to the `Trainer`.\n",
        "\n",
        "The `Trainer` object now encapsulates all the necessary information for fine-tuning the BERT model on the IMDB dataset."
      ],
      "metadata": {
        "id": "OTa3wuDx8k4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kyzU-ee8soe"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O4RXQsM25if"
      },
      "source": [
        "## Create the Trainer with Early Stopping\n",
        "\n",
        "This cell creates a `Trainer` object, similar to the previous cell, but with the addition of an early stopping callback. Early stopping is a technique to prevent overfitting by monitoring the model's performance on a validation set during training.\n",
        "\n",
        "\n",
        "Here's what this code does:\n",
        "\n",
        "* **Import `EarlyStoppingCallback`:** Imports the callback class for early stopping.\n",
        "* **Instantiate `Trainer`:** Creates an instance of the `Trainer` class, just like before.\n",
        "* **Add early stopping callback:** Adds the `EarlyStoppingCallback` to the `Trainer`. The `early_stopping_patience` parameter determines how many evaluations to wait for improvement before stopping the training.\n",
        "\n",
        "**How Early Stopping Works**\n",
        "\n",
        "Early stopping helps avoid overfitting by monitoring the validation loss during training. If the model's performance on the validation set doesn't improve after a certain number of evaluations (specified by `early_stopping_patience`), the training stops early, preventing the model from learning the training data too well and losing its ability to generalize to new data.\n",
        "\n",
        "\n",
        "### Note on Using Weights & Biases (wandb) for Logging\n",
        "\n",
        "The default setup in this notebook has `wandb` (Weights & Biases) logging **disabled**. This is done to simplify the setup for users who do not require experiment tracking or prefer not to use external services. However, `wandb` provides a powerful interface for logging metrics, comparing experiment runs, and visualizing performance.\n",
        "\n",
        "---\n",
        "\n",
        "### Disabling wandb by Default\n",
        "By default, `wandb` logging is turned off by setting `report_to=\"none\"` in the `TrainingArguments`. Here's the code block for training without `wandb`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtOETwok1AXW"
      },
      "outputs": [],
      "source": [
        "# Early stopping helps avoid overfitting by monitoring the validation loss during training.\n",
        "# If the model doesn't improve after 'early_stopping_patience' number of evaluations, the training stops early.\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments,EarlyStoppingCallback\n",
        "trainer = Trainer(\n",
        "    model=model,                         # The pre-trained BERT model\n",
        "    args=training_args,                  # Training arguments defined earlier\n",
        "    train_dataset=train_dataset,         # Training dataset\n",
        "    eval_dataset=val_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],  # Add early stopping callback\n",
        "    report_to=\"none\"  # Disables wandb\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional: Enable Weights & Biases (wandb) for Experiment Tracking\n",
        "\n",
        "This code block shows how to enable **Weights & Biases (wandb)** for logging and monitoring your model's training progress. Wandb provides a web interface that allows you to visualize metrics, such as loss and accuracy, in real time.\n",
        "\n",
        "To use wandb, you will need to create an account and generate an API token. If you choose to use wandb, make sure to uncomment the lines below and set up your wandb project.\n",
        "\n",
        "- If you prefer not to use wandb, you can simply leave the lines commented out, or you can configure the `Trainer` to report to \"none\" by setting `report_to=\"none\"` in the `TrainingArguments`.\n",
        "\n",
        "### Steps to Obtain Your wandb API Token\n",
        "\n",
        "1. **Visit the wandb Website**:\n",
        "   - Go to the [Weights & Biases website](https://wandb.ai/site).\n",
        "\n",
        "2. **Create an Account**:\n",
        "   - If you don’t have an account yet, click on **\"Sign Up\"** and fill in the required details.\n",
        "   - If you already have an account, simply **log in**.\n",
        "\n",
        "3. **Access Your API Key**:\n",
        "   - Click on your **profile icon** in the top-right corner of the page.\n",
        "   - Select **\"Settings\"** from the dropdown menu.\n",
        "   - Scroll down to find the **\"API Keys\"** section.\n",
        "\n",
        "4. **Copy Your API Key**:\n",
        "   - Your API key will be displayed here.\n",
        "   - Click **\"Copy\"** to copy the API key to your clipboard.\n",
        "\n",
        "5. **Use the API Key in Your Code**:\n",
        "   - In your Colab or Jupyter Notebook, use the following code to log in:\n",
        "     ```python\n",
        "     import wandb\n",
        "     wandb.login(key=\"your_api_key_here\")\n",
        "     ```\n",
        "   - Replace `\"your_api_key_here\"` with the API key you copied."
      ],
      "metadata": {
        "id": "sAgU2bUBIGcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments,EarlyStoppingCallback\n",
        "# trainer = Trainer(\n",
        "#     model=model,                         # The pre-trained BERT model\n",
        "#     args=training_args,                  # Training arguments defined earlier\n",
        "#     train_dataset=train_dataset,         # Training dataset\n",
        "#     eval_dataset=val_dataset,\n",
        "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],  # Add early stopping callback\n",
        "#     report_to=\"wandb\"  # Enable wandb\n",
        "# )"
      ],
      "metadata": {
        "id": "60R5CY3bH-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUzHyCoYrvHD"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "This cell starts the fine-tuning process. The `trainer.train()` method initiates the training loop, where the model learns to classify movie reviews as positive or negative.\n",
        "\n",
        "**Training Time**\n",
        "\n",
        "The training process might take a while to complete, depending on factors like the dataset size, the number of training epochs, and the available hardware. With the default parameter values, it is expected to take a couple of hours to complete on Colab's free-tier GPU.\n",
        "\n",
        "**Training Output**\n",
        "\n",
        "During training, you'll see output that shows the progress, including:\n",
        "\n",
        "* **Step:** The current training step (iteration).\n",
        "* **Training Loss:** A measure of how well the model is fitting the training data.\n",
        "* **Validation Loss:** A measure of how well the model is generalizing to unseen data (the validation set).\n",
        "\n",
        "The goal is to minimize both the training loss and the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "WDxBgA3C28OR",
        "outputId": "f6bc9fed-5de3-4111-ca21-311cd16fd31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241104_132128-up8kfo2k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tm101test-none/huggingface/runs/up8kfo2k' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/tm101test-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tm101test-none/huggingface' target=\"_blank\">https://wandb.ai/tm101test-none/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tm101test-none/huggingface/runs/up8kfo2k' target=\"_blank\">https://wandb.ai/tm101test-none/huggingface/runs/up8kfo2k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3500/7500 57:21 < 1:05:35, 1.02 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.348600</td>\n",
              "      <td>0.302999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.305400</td>\n",
              "      <td>0.272669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.167700</td>\n",
              "      <td>0.241346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>0.221074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.137200</td>\n",
              "      <td>0.201637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>0.279495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.102300</td>\n",
              "      <td>0.253804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3500, training_loss=0.2482180519104004, metrics={'train_runtime': 3489.4987, 'train_samples_per_second': 34.389, 'train_steps_per_second': 2.149, 'total_flos': 7367109550080000.0, 'train_loss': 0.2482180519104004, 'epoch': 1.4})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCb8c_pJ2_pB"
      },
      "source": [
        "## Evaluate the Model\n",
        "\n",
        "After the fine-tuning process is complete, it's essential to evaluate the model's performance on the validation set. This gives you an estimate of how well the model will generalize to new, unseen data.\n",
        "\n",
        "This cell uses the `trainer.evaluate()` method to evaluate the model on the validation set. It returns a dictionary of evaluation metrics, such as accuracy, precision, recall, and F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "jz7OKD922_B6",
        "outputId": "57716167-8e42-4250-bd14-cb69baf30c6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 02:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "eval_results = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Evaluation Results\n",
        "\n",
        "This cell prints the evaluation results obtained in the previous step. It specifically focuses on the validation accuracy, which is a key metric for assessing the model's performance on unseen data.\n",
        "\n",
        "The `eval_results` dictionary contains various metrics, and this code extracts and prints the accuracy value."
      ],
      "metadata": {
        "id": "L5qHGQYn98K3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKVt5x1s3F0l",
        "outputId": "a45d5af1-0bd8-4d29-bbc5-7a732bbf8681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: {'eval_loss': 0.20163710415363312, 'eval_runtime': 133.1836, 'eval_samples_per_second': 75.084, 'eval_steps_per_second': 4.693, 'epoch': 1.4}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Validation Accuracy: {eval_results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djq_nYQfodcq"
      },
      "source": [
        "## Fine-tuned Model Performance\n",
        "\n",
        "This cell dives deeper into evaluating the performance of the fine-tuned BERT model. It calculates additional metrics beyond just accuracy to provide a more comprehensive assessment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaK7E-9GEJjO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7445ed0b-6456-4dca-b758-d9b93fa55726"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9259\n",
            "Precision: 0.9272\n",
            "Recall: 0.9229\n",
            "F1-Score: 0.9251\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Generate predictions and true labels\n",
        "predictions, labels, _ = trainer.predict(val_dataset)\n",
        "\n",
        "# Convert predictions to a PyTorch tensor and then apply argmax\n",
        "predicted_classes = torch.tensor(predictions).argmax(dim=1)\n",
        "\n",
        "# Convert labels to tensor if they are not already\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(labels, predicted_classes)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(labels, predicted_classes, average='binary')\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Model Performance Test"
      ],
      "metadata": {
        "id": "j1WWzVGTh2b6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_aKQZ4HXH0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e91c53-ba6c-46a1-9451-2ffd3fa05140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting base BERT model evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing validation data...\n",
            "Evaluating base model...\n",
            "\n",
            "Base BERT Model Performance (No Fine-tuning):\n",
            "Validation Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Recall: 0.9999\n",
            "F1-Score: 0.6666\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "def tokenize_and_prepare_data(df, tokenizer, max_length=256):\n",
        "    \"\"\"\n",
        "    Tokenize the text data and prepare it for BERT\n",
        "    \"\"\"\n",
        "    # Tokenize all reviews\n",
        "    encoded_data = tokenizer(\n",
        "        df['review'].tolist(),\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Convert labels to tensor\n",
        "    df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "    labels = torch.tensor(df['label'].tolist())\n",
        "\n",
        "    return encoded_data['input_ids'], encoded_data['attention_mask'], labels\n",
        "\n",
        "def evaluate_base_bert(val_df, batch_size=16, max_length=256):\n",
        "    # Load the tokenizer and base model\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    base_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    base_model = base_model.to(device)\n",
        "    base_model.eval()  # Set to evaluation mode\n",
        "\n",
        "    # Tokenize and prepare the validation data\n",
        "    print(\"Tokenizing validation data...\")\n",
        "    val_inputs, val_masks, val_labels = tokenize_and_prepare_data(val_df, tokenizer, max_length)\n",
        "\n",
        "    # Create DataLoader for validation set\n",
        "    val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "    val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "    # Lists to store predictions and true labels\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Evaluating base model...\")\n",
        "    # Evaluate without gradient computation\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            # Unpack the batch and move to GPU\n",
        "            batch_inputs, batch_masks, batch_labels = [b.to(device) for b in batch]\n",
        "\n",
        "            # Get model outputs\n",
        "            outputs = base_model(batch_inputs, attention_mask=batch_masks)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Convert logits to predictions\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # Move predictions and labels to CPU for metric calculation\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nBase BERT Model Performance (No Fine-tuning):\")\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Run the evaluation\n",
        "print(\"Starting base BERT model evaluation...\")\n",
        "base_metrics = evaluate_base_bert(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kNnL5ydh5T7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1c805b3f9be4f6ab3dfc4e6391e53d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebc0b9283b9944df94d93f3dd0b25de1",
              "IPY_MODEL_24c075f9ad234831812f4110667b420b",
              "IPY_MODEL_2cbae121875e455eab445274ed1c7f25"
            ],
            "layout": "IPY_MODEL_4be0ab76cf674a91815dade8093b0b57"
          }
        },
        "ebc0b9283b9944df94d93f3dd0b25de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3adb4c4afc30496298dac4b2a1ae8fba",
            "placeholder": "​",
            "style": "IPY_MODEL_a1607cecfd00477aa839b1965a9bd6be",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "24c075f9ad234831812f4110667b420b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a685253f9323487188168eaecffc20f9",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbc803c3ae04423b9f685ca1528188f6",
            "value": 48
          }
        },
        "2cbae121875e455eab445274ed1c7f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ac20b8957149fa81e5e143b7667ef2",
            "placeholder": "​",
            "style": "IPY_MODEL_e3748f3465264549b833639a4af46cea",
            "value": " 48.0/48.0 [00:00&lt;00:00, 989B/s]"
          }
        },
        "4be0ab76cf674a91815dade8093b0b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3adb4c4afc30496298dac4b2a1ae8fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1607cecfd00477aa839b1965a9bd6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a685253f9323487188168eaecffc20f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc803c3ae04423b9f685ca1528188f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72ac20b8957149fa81e5e143b7667ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3748f3465264549b833639a4af46cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a22d610c4d44f23ae39fc881cdea4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ef683bc18b74093b1726d1d35c121cb",
              "IPY_MODEL_2376b28c58324d86ab756547995269b5",
              "IPY_MODEL_7cb921148c514cd8b43c88af451b04ab"
            ],
            "layout": "IPY_MODEL_5fcde940ca424009900586ba01582581"
          }
        },
        "6ef683bc18b74093b1726d1d35c121cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94173eb3858c4aed837e696075621b3a",
            "placeholder": "​",
            "style": "IPY_MODEL_c5337660558e4af297d3ccbcecb857da",
            "value": "vocab.txt: 100%"
          }
        },
        "2376b28c58324d86ab756547995269b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_486595e6c9784687b3c3057c3a9b3ff8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82d61bef313746ccb84ff4ef2c504ea5",
            "value": 231508
          }
        },
        "7cb921148c514cd8b43c88af451b04ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cfd57048fc4413c87b90888a6aa6dda",
            "placeholder": "​",
            "style": "IPY_MODEL_c2f98f7e4c4c494eb2efa3c5abfad4c2",
            "value": " 232k/232k [00:00&lt;00:00, 1.61MB/s]"
          }
        },
        "5fcde940ca424009900586ba01582581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94173eb3858c4aed837e696075621b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5337660558e4af297d3ccbcecb857da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "486595e6c9784687b3c3057c3a9b3ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d61bef313746ccb84ff4ef2c504ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cfd57048fc4413c87b90888a6aa6dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f98f7e4c4c494eb2efa3c5abfad4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a51826a82a443f4aea03084a6d7a50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2caab0d9d51459c93fcc02250a05ca9",
              "IPY_MODEL_74b133ba7b404c208b2b912e29016c81",
              "IPY_MODEL_e2c0fa0051634b339719bcbbd2cfb5bb"
            ],
            "layout": "IPY_MODEL_d16c844b265f4e2b9026285ca8d47d40"
          }
        },
        "b2caab0d9d51459c93fcc02250a05ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f57d4edf074791a9ccacc662724a8f",
            "placeholder": "​",
            "style": "IPY_MODEL_d8b306981b6f4f418c17491538094cea",
            "value": "tokenizer.json: 100%"
          }
        },
        "74b133ba7b404c208b2b912e29016c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90f01cda9dc84d8b8298c7056f703a71",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e240316149b74600810640d7f78bdd05",
            "value": 466062
          }
        },
        "e2c0fa0051634b339719bcbbd2cfb5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a2c263e2da04ad9ae46055dfa094a89",
            "placeholder": "​",
            "style": "IPY_MODEL_794f0d276d1547db9055f056c9cb3c93",
            "value": " 466k/466k [00:00&lt;00:00, 7.20MB/s]"
          }
        },
        "d16c844b265f4e2b9026285ca8d47d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f57d4edf074791a9ccacc662724a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b306981b6f4f418c17491538094cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f01cda9dc84d8b8298c7056f703a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e240316149b74600810640d7f78bdd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a2c263e2da04ad9ae46055dfa094a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794f0d276d1547db9055f056c9cb3c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "560827baa14e478bb1ca555efbb7d043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25515eb1d22e401d9217324b835beef5",
              "IPY_MODEL_d4c00a65761f42a68244f63414743b8c",
              "IPY_MODEL_6ed102c22bc54748a459a2142f3a1891"
            ],
            "layout": "IPY_MODEL_f84efdcfed264190bf30196b9212f01b"
          }
        },
        "25515eb1d22e401d9217324b835beef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2e32bfbeae48829793ce503022d4d7",
            "placeholder": "​",
            "style": "IPY_MODEL_20e402c074aa4f21a4504983f301a31c",
            "value": "config.json: 100%"
          }
        },
        "d4c00a65761f42a68244f63414743b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2abb00a39d64a00801acbb1f69f1067",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2a4201f8ca9437b979598180d654dcf",
            "value": 570
          }
        },
        "6ed102c22bc54748a459a2142f3a1891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8114b5aa2db94ee886524244e3093fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_e563c60497b844069bfc57b1322b99b7",
            "value": " 570/570 [00:00&lt;00:00, 6.18kB/s]"
          }
        },
        "f84efdcfed264190bf30196b9212f01b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2e32bfbeae48829793ce503022d4d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e402c074aa4f21a4504983f301a31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2abb00a39d64a00801acbb1f69f1067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a4201f8ca9437b979598180d654dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8114b5aa2db94ee886524244e3093fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e563c60497b844069bfc57b1322b99b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84f046e75cde40e3a45d331aeab3bce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5300624331a8478c969eb8e7ce6589e2",
              "IPY_MODEL_284fb5d182264ef5b35d513ce01a22f3",
              "IPY_MODEL_a5a62ab1ffcb4b478436b7139bced883"
            ],
            "layout": "IPY_MODEL_6fe625d128cf40e49079a8e209abe2c1"
          }
        },
        "5300624331a8478c969eb8e7ce6589e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6573859f5e8f498fbc068d8cb07f6e54",
            "placeholder": "​",
            "style": "IPY_MODEL_6c25fa552d484366a15ad0cd41f94926",
            "value": "model.safetensors: 100%"
          }
        },
        "284fb5d182264ef5b35d513ce01a22f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c691a139c88744f28f6285d210b05154",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd8bc091dd71488bafaba01150f8c5d2",
            "value": 440449768
          }
        },
        "a5a62ab1ffcb4b478436b7139bced883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb12c92a63724c0fbe5e01659a09b622",
            "placeholder": "​",
            "style": "IPY_MODEL_7498e23213b445e9bce845d04f213f63",
            "value": " 440M/440M [00:02&lt;00:00, 242MB/s]"
          }
        },
        "6fe625d128cf40e49079a8e209abe2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6573859f5e8f498fbc068d8cb07f6e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c25fa552d484366a15ad0cd41f94926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c691a139c88744f28f6285d210b05154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8bc091dd71488bafaba01150f8c5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb12c92a63724c0fbe5e01659a09b622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7498e23213b445e9bce845d04f213f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}